{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import nltk\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             keyword                                               text  \\\n",
      "index                                                                     \n",
      "0             weapon  @DwarfOnJetpack I guess I can say you and me m...   \n",
      "1      forest%20fire  E1.1.2 Particulate=Break up of Solid Combust F...   \n",
      "2               army  7.Beyonce Is my pick for http://t.co/thoYhrHkf...   \n",
      "3          explosion  @KirCut1 lets get a dope picture together and ...   \n",
      "4             deaths  Breast milk is the original #superfood but rat...   \n",
      "\n",
      "       target  \n",
      "index          \n",
      "0           0  \n",
      "1           1  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('Data/train_data.csv',index_col='index').reset_index() \n",
    "test_data = pd.read_csv('Data/test_data.csv', index_col='index')\n",
    "train_data.drop(columns='index',inplace=True) \n",
    "\n",
    "train_data.head() \n",
    "print( test_data.head() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating letters case and ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-bc55184f957c>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['text'] = train_data['text'].str.replace('\\W',' ')\n",
      "<ipython-input-4-bc55184f957c>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['text'] = test_data['text'].str.replace('\\W', ' ').str.lower().str.split()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data['text'] = train_data['text'].str.replace('\\W',' ')\n",
    "train_data['text'] = train_data['text'].str.lower() \n",
    "test_data['text'] = test_data['text'].str.replace('\\W', ' ').str.lower().str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emergency%20services</td>\n",
       "      <td>goulburn man henry van bilsen missing  emergen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>the things we fear most in organizations  fluc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tsunami</td>\n",
       "      <td>tsunami_esh    hey esh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drown</td>\n",
       "      <td>potus you until you drown by water entering t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wounds</td>\n",
       "      <td>crawling in my skin these wounds they will not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                keyword                                               text  \\\n",
       "0  emergency%20services  goulburn man henry van bilsen missing  emergen...   \n",
       "1                  fear  the things we fear most in organizations  fluc...   \n",
       "2               tsunami                             tsunami_esh    hey esh   \n",
       "3                 drown   potus you until you drown by water entering t...   \n",
       "4                wounds  crawling in my skin these wounds they will not...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting our text and adding to our dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [goulburn, man, henry, van, bilsen, missing, e...\n",
      "1       [the, things, we, fear, most, in, organization...\n",
      "2                                 [tsunami_esh, hey, esh]\n",
      "3       [potus, you, until, you, drown, by, water, ent...\n",
      "4       [crawling, in, my, skin, these, wounds, they, ...\n",
      "                              ...                        \n",
      "6085              [justinbieber, arianagrande, screaming]\n",
      "6086    [how, to, survive, in, the, markets, http, t, ...\n",
      "6087    [look, at, them, ayhoka_, co, happy, bn, too, ...\n",
      "6088    [waseembadami, condemning, of, deaths, more, t...\n",
      "6089    [thelegendblue, cozmo23, they, ll, probably, a...\n",
      "Name: text, Length: 6090, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data['text'] = train_data['text'].str.split() \n",
    "print(train_data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_small_words = lambda l : [ i for i in l if len(i)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goulburn',\n",
       " 'man',\n",
       " 'henry',\n",
       " 'van',\n",
       " 'bilsen',\n",
       " 'missing',\n",
       " 'emergency',\n",
       " 'services',\n",
       " 'are',\n",
       " 'searching',\n",
       " 'for',\n",
       " 'goulburn',\n",
       " 'man',\n",
       " 'who',\n",
       " 'disappeared',\n",
       " 'from',\n",
       " 'his',\n",
       " 'http',\n",
       " 'z99pkjztrp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_small_words(train_data['text'].values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(remove_small_words)\n",
    "test_data['test'] = test_data['text'].apply(remove_small_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary= [ w for txt in train_data['text'].values.tolist() for w in txt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = { unique_word: [0]*len(train_data['text']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, txt in enumerate(train_data['text']):\n",
    "    for word in txt:\n",
    "        word_counts[word][index] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_counts = pd.DataFrame(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_set =  [ (dict({\"words\" :tuple(w)}) , t)  for w, t in zip(train_data[\"text\"], train_data['target'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(tr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_set =  [ (dict({\"words\" :tuple(w)}) , t)  for w, t in zip(test_data[\"text\"], train_data['target'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 57.91201575837164\n"
     ]
    }
   ],
   "source": [
    "print(\"Acc:\" , (nltk.classify.accuracy(classifier,ts_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   words = ('the', 'prophet', 'peace', 'upon', 'him', 'said', 'save', 'yourself', 'from', 'hellfire', 'even', 'giving', 'half', 'date', 'charity')      0 : 1      =      2.6 : 1.0\n",
      "                   words = ('fight', 'bioterrorism', 'sir')      1 : 0      =      1.9 : 1.0\n",
      "                   words = ('foodscare', 'offers2go', 'nestleindia', 'slips', 'into', 'loss', 'after', 'magginoodle', 'ban', 'unsafe', 'and', 'hazardous', 'for', 'humanconsumption')      1 : 0      =      1.9 : 1.0\n",
      "                   words = ('came', 'land', 'which', 'was', 'engulfed', 'tribal', 'war', 'and', 'turned', 'into', 'land', 'peace', 'madinah', 'prophetmuhammad', 'islam')      0 : 1      =      1.6 : 1.0\n",
      "                   words = ('allah', 'describes', 'piling', 'wealth', 'thinking', 'would', 'last', 'forever', 'the', 'description', 'the', 'people', 'hellfire', 'surah', 'humaza', 'reflect')      0 : 1      =      1.4 : 1.0\n",
      "                   words = ('hellfire', 'surrounded', 'desires', 'careful', 'and', 'don', 'ûªt', 'let', 'your', 'desires', 'control', 'you', 'afterlife')      0 : 1      =      1.4 : 1.0\n",
      "                   words = ('this', 'the', 'natural', 'and', 'unavoidable', 'consequence', 'socialism', 'everywhere', 'has', 'been', 'tried', 'http', 'bbdpnj8xsx')      0 : 1      =      1.4 : 1.0\n",
      "                   words = ('who', 'bringing', 'the', 'tornadoes', 'and', 'floods', 'who', 'bringing', 'the', 'climate', 'change', 'god', 'after', 'america', 'plaguing', 'her', 'farrakhan', 'quote')      0 : 1      =      1.4 : 1.0\n",
      "                   words = ('caution', 'breathing', 'may', 'hazardous', 'your', 'health')      1 : 0      =      1.2 : 1.0\n",
      "                   words = ('hellfire', 'don', 'ûªt', 'even', 'want', 'think', 'about', 'mention', 'let', 'ûªs', 'not', 'anything', 'that', 'leads', 'islam')      1 : 0      =      1.2 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8abf314177e09d491ffeb76f18407c17dd57399bceea11d775887f9f21caad0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
